{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projeto2_perceptrons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpRsasVd9eoyfVKN+/eIr5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malbouis/Python_intro/blob/master/aulas_2021-1/Projeto2_perceptrons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5vP_ogRktgm"
      },
      "source": [
        "# Projeto 2 - Perceptrons\n",
        "\n",
        "Nesse segundo projeto da disciplina de Introdução a Python, vamos construir uma classe de um modelo de Redes Neurais, que é a base das Redes Neurais clássicas e Redes Neurais Profundas (Deep Learning), chamado Peceptron.\n",
        "\n",
        "No mundo atual, o aprendizado de máquina está presente em muitas tecnologias à nossa volta: classificação de bilhões de imagens (por exemplo, Google Images), reconhecimento de fala (por exemplo, a Siri da Apple), recomendação de vídeos no YouTube, entre muitas outras.\n",
        "\n",
        "![Aprendizado Supervisionado](https://miro.medium.com/max/1400/1*eEKb2RxREV6-MtLz2DNWFQ.gif)\n",
        "\n",
        "O Perceptron é uma das arquiteturas de Redes Neurais Artificiais mais simples que existem. Foi inventado em 1957 por Frank Rosenblatt. \n",
        "\n",
        "Para entender como um Perceptron funciona, vamos começar com um esquema do perceptron original, sem muitos detalhes. \n",
        "\n",
        "O Perceptron:\n",
        "* toma alguns inputs, \n",
        "* faz um processamento \n",
        "* retorna um único output.\n",
        "\n",
        "![perceptrons](https://raw.githubusercontent.com/malbouis/Python_intro/master/aulas_2020-1/pics/perceptrons%201.png)\n",
        "\n",
        "Antes de continuar, vamos pensar em um exemplo concreto.\n",
        "\n",
        "Vamos considerar um conjunto de dados de flores Iris, e suas três espécies: Iris-Setosa, Iris-Versicolor e Iris-Virgina, que têm as seguintes características:\n",
        "* comprimento e largura da sépala;\n",
        "* comprimento e largura da pétala.\n",
        "\n",
        "**Iris dataset**: Famoso conjunto de dados com o comprimento e a largura das pétalas e sépalas de 150 flores Iris de 3 espécies diferentes: Iris-Setosa, Iris-Versicolor e Iris-Virginica.\n",
        "\n",
        "![](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Machine+Learning+R/iris-machinelearning.png)\n",
        "\n",
        "### Funcionamento do Perceptron\n",
        "\n",
        "Podemos pensar no Perceptron como um mecanismo que toma como input as *features* (características) de uma Iris (comprimento e largura da sépala e da pétala) e nos retorna a **classificação** da espécie da flor, ou a maior probabilidade de que seja de uma dada espécie.\n",
        "\n",
        "É importante notar que o Perceptron tem um comportamento **binário**, ou seja, só podemos comparar *duas* espécies de flores com o Perceptron.\n",
        "\n",
        "Na nossa representação simples do perceptron acima, teríamos:\n",
        "\n",
        "![](https://raw.githubusercontent.com/malbouis/Python_intro/master/aulas_2020-1/pics/perceptrons2.png)\n",
        "\n",
        "#### Processamento\n",
        "\n",
        "O Processamento do Perceptron, é onde se dá a decisão do mecanismo. \n",
        "\n",
        "A fórmula para a decisão do neurônio perceptron é relativamente simples:\n",
        "\n",
        "$\n",
        "    output=\\left\\{\n",
        "                \\begin{array}{ll}\n",
        "                  0, se \\sum_j w_j x_j \\leq b\\\\\n",
        "                  1, se \\sum_j w_j x_j > b\\\\\n",
        "                \\end{array}\n",
        "              \\right.\n",
        "  $\n",
        "\n",
        "Essa fórmula é conhecida como *Heaviside stepfunction*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9ymCQOFAxHaf",
        "outputId": "863f3118-efad-46a2-fd95-fb97b0f7fa8c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace (-1.5,1.5)\n",
        "y = np.heaviside(x,0)\n",
        "\n",
        "plt.plot(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4c0c9cdcc0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EV3Wrapyk2t"
      },
      "source": [
        "A fórmula de decisão do neurônio (perceptron), também é chamada de **função de ativação**.\n",
        "\n",
        "Podemos reescrevê-la da seguinte forma:\n",
        "\n",
        "$\n",
        "    ativação=\\left\\{\n",
        "                \\begin{array}{ll}\n",
        "                  1, se \\sum_j w_j x_j + b > 0\\\\\n",
        "                  0, se \\sum_j w_j x_j + b \\leq 0\\\\\n",
        "                \\end{array}\n",
        "              \\right.\n",
        "  $\n",
        "\n",
        "Podemos incorporar b no somatório da primeira linha da equação acima, considerando: $w_0=b$ e $x_0 = 1$. Sendo assim, a função de ativação pode ser reescrita como:\n",
        "\n",
        "$\n",
        "    f(x)=\\left\\{\n",
        "                \\begin{array}{ll}\n",
        "                  1, se \\sum_{j=0}^{N} w_j x_j > 0\\\\\n",
        "                  0, para \\; o \\; resto\\\\\n",
        "                \\end{array}\n",
        "              \\right.\n",
        "  $\n",
        "\n",
        "E assim incorporamos o $b$, que também é conhecido como **bias**, como  peso $w_0 = b$ do input $x_0=1$ do nosso peceptron, que vai tomando corpo:\n",
        "\n",
        "![](https://raw.githubusercontent.com/malbouis/Python_intro/master/aulas_2020-1/pics/perceptrons4.png)\n",
        "\n",
        "\n",
        "Por simplicidade, usaremos a função de ativação de Heaviside, entretanto essa função pode variar. Pode ser, por exemplo, uma função [*sigmoide*](https://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_sigmoide)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F10ZKPulxGNt"
      },
      "source": [
        "## Como se dá a classificação das Iris? Ou, como os perceptrons aprendem?\n",
        "\n",
        "\n",
        "O primeiro passo é **treinar** o nosso Perceptron: em um conjunto de dados em que **sabemos as espécies das Iris a priori**;\n",
        "\n",
        "### Treino\n",
        "\n",
        "Para cada **conjunto de inputs** (features):\n",
        "   1. Compararamos o output ($f(x)$, a classificação do nosso perceptron, que chamaremos de **prediction**) com a espécie real da flor (chamaremos de y e identificaremos como **label**);\n",
        "   1. Baseados no **resultado da comparação entre prediction e label**, devemos **ajustar os pesos** caso o perceptron não esteja acertando corretamente a classificação.\n",
        "   1. O último passo é **testar** o nosso perceptron: em um outro conjunto de dados, comparamos a classificação fornecida pelo perceptron com a real espécie da flor (**label**);\n",
        "\n",
        "### Prediction\n",
        "\n",
        "A predição do perceptron é calculada pela função de ativação. No nosso exemplo, ela é a *Heaviside Stepfunction*, que escrevemos acima:\n",
        "\n",
        "$\n",
        "    f(x)=\\left\\{\n",
        "                \\begin{array}{ll}\n",
        "                  1, se \\sum_{j=0}^{N} w_j x_j > 0\\\\\n",
        "                  0, para \\; o \\; resto\\\\\n",
        "                \\end{array}\n",
        "              \\right.\n",
        "  $\n",
        "\n",
        "* Note que tanto os inputs quanto os pesos são matrizes (ou arrays), logo o produto do somatório é um produto matricial (ou escalar). *Dica: o numpy tem uma função [numpy.dot](https://numpy.org/doc/stable/reference/generated/numpy.dot.html) que implementa produto escalar.* \n",
        "\n",
        "* Note também que na nossa construção do perceptron, o primeiro elemento do array dos inputs é o número 1 e o primeiro elemento do array dos pesos é o b (**bias**).\n",
        "\n",
        "### Comparação entre prediction / label e ajuste do perceptron\n",
        "\n",
        "Consideremos que o nosso perceptron teve um output, $f(x)$ e que o output esperado (o real, do qual nós temos a informação a priori, o label) é $y$.\n",
        "\n",
        "A comparação entre o output esperado e o obtido é simplesmente:\n",
        "\n",
        "`e = output_esperado - output_obtido`\n",
        "\n",
        "ou\n",
        "\n",
        "$e = y - f(x)$\n",
        "\n",
        "O que queremos é rodar o perceptron sobre os inputs até que a diferença acima (ou o erro na predição) seja o menor possível.\n",
        "\n",
        "A melhor forma de fazer isso é corrigindo os pesos de cada input, pelo erro de predição.\n",
        "\n",
        "### Ajuste dos pesos\n",
        "\n",
        "O ajuste dos pesos é dado por:\n",
        "\n",
        "$w \\rightarrow w + lr*e*x$\n",
        "\n",
        "onde \n",
        "\n",
        "`lr`: learning rate\n",
        "\n",
        "`e`: erro do output em relação ao label\n",
        "\n",
        "`x`: conjunto de inputs (features)\n",
        "\n",
        "\n",
        "Essa atualização dos pesos é feita de forma iterativa e o número de iterações é determinado pelo que chamamos de **threshold**, também conhecido como **época**.\n",
        "\n",
        "\n",
        "## PROJETO\n",
        "\n",
        "1. Criar uma `Classe` Perceptron em Python. Vocês podem seguir o esqueleto de Classe apresentado abaixo.\n",
        "\n",
        "2. Aplique essa classe nos dados das flores Iris para determinar se uma Iris com um certo comprimento e largura da **pétala** é uma Iris Setosa.\n",
        "\n",
        "3. Compare o resultado da sua classe com a classe Peceptron do módulo do scikit-learn `linear_model`.\n",
        "\n",
        "4. Você pode pensar em algum outro exemplo em que possa aplicar o modelo do Perceptron? Quando esse modelo falha?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JDBy4GmuHeT"
      },
      "source": [
        "## ESQUELETO DE CLASSE PERCEPTRON\n",
        "import numpy as np\n",
        "\n",
        "class MyPerceptron():\n",
        "\n",
        "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
        "        '''\n",
        "        método de inicialização que tem os seguintes atributos:\n",
        "        no_of_inputs: número de features passadas como input ao perceptron\n",
        "        threshold: número de iterações de atualização do peso\n",
        "        learning_rate: taxa com a qual os pesos são atualizados a cada iteração\n",
        "        weights: inicialização dos pesos (dica: pode inicializar com método np.zeros). Não se esquecer que o vetor dos pesos\n",
        "        terá no_of_inputs + 1 elementos por conta do bias que é o primeiro elemento.\n",
        "        '''\n",
        "        \n",
        "           \n",
        "    def predict(self, inputs):\n",
        "      '''\n",
        "      método de implementação da função de ativação.\n",
        "      inputs: array com o conjunto de inputs (features). No projeto pedimos que considerassem o comprimento e largura da pétala da Iris.\n",
        "      Não se esquecer que o produto da função de ativação é um produto escalar e pode ser calculado pelo método np.dot\n",
        "      '''\n",
        "        \n",
        "\n",
        "    def train(self, training_inputs, labels):\n",
        "      '''\n",
        "      método de treino. É aqui que os pesos são atualizados um certo número de vezes (determinado pelo valor do threshold).\n",
        "      Nesse método é feita a comparação entre o resultado da função de ativação (predição) e\n",
        "      o resultado esperado (label).\n",
        "      O método deve atualizar tanto os pesos quanto o bias (lembre que o bias é o primeiro valor do vetor peso e tem input 1.)\n",
        "      A atualização é feita iterativamente um número (threshold) de vezes.\n",
        "      '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrqxx1RXgRlH",
        "outputId": "f511953e-c055-43f7-d4a8-e9ad2f332bdd"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "iris = load_iris() # returns a dictionary-like object\n",
        "# características (features) das flores Iris:\n",
        "print(iris.target_names)    # target = label\n",
        "print(iris.feature_names)\n",
        "\n",
        "# Pelo primeiro print acima, as features são: 0: sepal length, 1: sepal width, 2: petal length, 3: petal width\n",
        "# Vamos selecionar somente as features petal length e petal width:\n",
        "X = iris.data[:, (2,3)]  # nos retorna um array com 150 conjuntos de inputs\n",
        "#len(iris.data[:,(2,3)])\n",
        "y = (iris.target == 0).astype(int)  # label = iris setosa. Retorna uma lista com os labels da Iris-Setosa. 0: não, 1: sim\n",
        "print(\"iris setosa classification: \", y)\n",
        "\n",
        "perceptron_clf = Perceptron()      # dois inputs: comprimento e largura da pétala\n",
        "perceptron_clf.fit(X,y)            # Train\n",
        "\n",
        "y_pred = perceptron_clf.predict([[1,0.5]])  # predict\n",
        "print(y_pred)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "iris setosa classification:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW5G6thqu9JX"
      },
      "source": [
        "# Modelo de como deve funcionar com a classe criada nesse projeto\n",
        "\n",
        "perceptron = MyPerceptron(2)\n",
        "X = iris.data[:, (2,3)]             # inputs\n",
        "y = (iris.target == 0).astype(int)  # label = iris setosa. Retorna uma lista com os labels da Iris-Setosa. 0: não, 1: sim\n",
        "#print(y)\n",
        "\n",
        "treino = perceptron.train(X,y)\n",
        "pred = perceptron.predict([1, 0.5])\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwHa1JfYPnag"
      },
      "source": [
        "No exemplo acima, usamos somente dois inputs: o comprimento e a largura da pétala. \n",
        "* Você pode expandir o código para considerar também o comprimento e largura da sépala como features;\n",
        "* Você pode separar a amostra das Iris em duas: uma para treino e outra para teste. O scikit-learn tem um método que faz isso pra você: o `train_test_slit`; Compare cada uma das Iris de teste com o label ==> coloque o resultado em um gráfico (classificação versus label);\n",
        "* **Ponto extra** para quem implementar a função de ativação sigmoid no lugar da Heaviside e/ou melhorar a estimativa do erro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRa5a1oDlP6o"
      },
      "source": [
        "## Referências:\n",
        "\n",
        "1. Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow, Aurélion Géron, O'Reilly;\n",
        "1. *Introdução ao numpy*: https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.pdf"
      ]
    }
  ]
}